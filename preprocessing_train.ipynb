{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die ersten 50000 vollständigen Einträge wurden in 'data/first_30_complete_entries.json' gespeichert.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#jason datei kleiner machen \n",
    "\n",
    "# Pfad zur Eingangs-JSON-Datei\n",
    "input_file_path = 'data/300k_books Kopie.json'\n",
    "# Pfad zur Ausgabedatei\n",
    "output_file_path = 'data/first_30_complete_entries.json'\n",
    "\n",
    "# Funktion zum Überprüfen, ob ein Eintrag vollständig ist\n",
    "def is_entry_complete(entry):\n",
    "    required_fields = ['isbn', 'text_reviews_count', 'country_code', 'language_code', 'average_rating', 'similar_books', 'description', 'format', 'link', 'authors', 'publisher', 'num_pages', 'publication_year', 'book_id', 'ratings_count', 'title']\n",
    "    return all(field in entry and entry[field] not in (None, \"\", []) for field in required_fields)\n",
    "\n",
    "# Liste zum Speichern der vollständigen Einträge\n",
    "complete_entries = []\n",
    "\n",
    "# Lesen der JSON-Datei\n",
    "with open(input_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        entry = json.loads(line.strip())\n",
    "        if is_entry_complete(entry):\n",
    "            complete_entries.append(entry)\n",
    "            if len(complete_entries) == 50000:  # Nur die ersten 30 Einträge speichern\n",
    "                break\n",
    "\n",
    "# Schreiben der vollständigen Einträge in die neue JSON-Datei\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for entry in complete_entries:\n",
    "        json.dump(entry, output_file)\n",
    "        output_file.write('\\n')\n",
    "\n",
    "print(f\"Die ersten 50000 vollständigen Einträge wurden in '{output_file_path}' gespeichert.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[{'isbn': '0743294297', 'text_reviews_count': '3282', 'series': [], 'country_code': 'US', 'language_code': 'eng', 'popular_shelves': [{'count': '7615', 'name': 'to-read'}, {'count': '728', 'name': 'chick-lit'}, {'count': '673', 'name': 'currently-reading'}, {'count': '404', 'name': 'fiction'}, {'count': '152', 'name': 'books-i-own'}, {'count': '119', 'name': 'jennifer-weiner'}, {'count': '82', 'name': 'chicklit'}, {'count': '76', 'name': 'owned'}, {'count': '72', 'name': 'book-club'}, {'count': '72', 'name': 'friendship'}, {'count': '55', 'name': 'adult-fiction'}, {'count': '54', 'name': 'chic-lit'}, {'count': '51', 'name': 'favorites'}, {'count': '50', 'name': 'adult'}, {'count': '43', 'name': 'contemporary'}, {'count': '39', 'name': 'read-in-2010'}, {'count': '37', 'name': 'library'}, {'count': '35', 'name': 'read-in-2009'}, {'count': '34', 'name': 'owned-books'}, {'count': '33', 'name': 'default'}, {'count': '29', 'name': 'women-s-fiction'}, {'count': '27', 'name': 'audiobooks'}, {'count': '26', 'name': 'contemporary-fiction'}, {'count': '26', 'name': 'audio'}, {'count': '26', 'name': 'beach-reads'}, {'count': '25', 'name': 'my-books'}, {'count': '25', 'name': 'audiobook'}, {'count': '23', 'name': 'romance'}, {'count': '23', 'name': 'general-fiction'}, {'count': '21', 'name': 'i-own'}, {'count': '20', 'name': 'audio-book'}, {'count': '20', 'name': 'humor'}, {'count': '18', 'name': 'read-in-2011'}, {'count': '18', 'name': 'ebooks'}, {'count': '18', 'name': 'womens-fiction'}, {'count': '18', 'name': 'kindle'}, {'count': '18', 'name': 'novels'}, {'count': '17', 'name': 'have'}, {'count': '16', 'name': 'did-not-finish'}, {'count': '16', 'name': 'read-2010'}, {'count': '16', 'name': 'drama'}, {'count': '15', 'name': 'read-in-2012'}, {'count': '15', 'name': 'audio-books'}, {'count': '15', 'name': 'guilty-pleasures'}, {'count': '15', 'name': 'book-club-books'}, {'count': '15', 'name': 'own-it'}, {'count': '14', 'name': 'to-buy'}, {'count': '13', 'name': 'read-2009'}, {'count': '12', 'name': 'books-i-have'}, {'count': '12', 'name': 'favorite-authors'}, {'count': '12', 'name': 'weiner'}, {'count': '11', 'name': 'read-in-2013'}, {'count': '11', 'name': 'own-to-read'}, {'count': '11', 'name': '2010-books'}, {'count': '11', 'name': 'library-book'}, {'count': '11', 'name': 'women'}, {'count': '10', 'name': 'relationships'}, {'count': '10', 'name': 'mystery'}, {'count': '10', 'name': 'fluff'}, {'count': '10', 'name': 'chick'}, {'count': '10', 'name': 'beach-read'}, {'count': '10', 'name': 'borrowed'}, {'count': '10', 'name': 'my-library'}, {'count': '10', 'name': '2009-reads'}, {'count': '10', 'name': 'wish-list'}, {'count': '10', 'name': 'want-to-read'}, {'count': '9', 'name': 'finished'}, {'count': '9', 'name': 'on-my-shelf'}, {'count': '9', 'name': 'didn-t-finish'}, {'count': '9', 'name': 'ebook'}, {'count': '9', 'name': '2009-books'}, {'count': '8', 'name': 'dysfunctional-families'}, {'count': '8', 'name': 'read-in-2015'}, {'count': '8', 'name': 'read-2011'}, {'count': '8', 'name': 'family'}, {'count': '8', 'name': 'abandoned'}, {'count': '8', 'name': 'light-reading'}, {'count': '8', 'name': 'e-books'}, {'count': '8', 'name': 'books-read-in-2010'}, {'count': '8', 'name': 'books-read-in-2009'}, {'count': '8', 'name': 'adult-books'}, {'count': '7', 'name': 'read-in-2016'}, {'count': '7', 'name': 'read-2015'}, {'count': '7', 'name': '2014-reads'}, {'count': '7', 'name': 'weiner-jennifer'}, {'count': '7', 'name': 'coming-of-age'}, {'count': '7', 'name': 'audible'}, {'count': '7', 'name': 'paperback'}, {'count': '7', 'name': 'books'}, {'count': '7', 'name': 'on-the-shelf'}, {'count': '7', 'name': 'purchased'}, {'count': '7', 'name': '2010-read'}, {'count': '7', 'name': 'lit'}, {'count': '7', 'name': 'already-own'}, {'count': '7', 'name': 'friends'}, {'count': '6', 'name': 'shelfari-favorites'}, {'count': '6', 'name': 'bullying'}, {'count': '6', 'name': 'tbr'}, {'count': '6', 'name': 'on-my-bookshelf'}, {'count': '6', 'name': 'bookworm-bitches'}], 'asin': '', 'is_ebook': 'false', 'average_rating': '3.49', 'kindle_asin': 'B002ENBLOK', 'similar_books': ['6604176', '6054190', '2285777', '82641', '7569453', '7010683', '5941079', '7052976', '227709', '6389685', '5456247', '3134684'], 'description': \"Addie Downs and Valerie Adler were eight when they first met and decided to be best friends forever. But, in the wake of tragedy and betrayal during their teenage years, everything changed. Val went on to fame and fortune. Addie stayed behind in their small Midwestern town. Destiny, however, had more in store for these two. And when, twenty-five years later, Val shows up at Addie's front door with blood on her coat and terror on her face, it is the beginning of a wild adventure for two women joined by love and history who find strength together that they could not find alone.\", 'format': 'Hardcover', 'link': 'https://www.goodreads.com/book/show/6066819-best-friends-forever', 'authors': [{'author_id': '9212', 'role': ''}], 'publisher': 'Atria Books', 'num_pages': '368', 'publication_day': '14', 'isbn13': '9780743294294', 'publication_month': '7', 'edition_information': '', 'publication_year': '2009', 'url': 'https://www.goodreads.com/book/show/6066819-best-friends-forever', 'image_url': 'https://s.gr-assets.com/assets/nophoto/book/111x148-bcc042a9c91a29c1d680899eff700a03.png', 'book_id': '6066819', 'ratings_count': '51184', 'work_id': '6243154', 'title': 'Best Friends Forever', 'title_without_series': 'Best Friends Forever'}, {'isbn': '0590417010', 'text_reviews_count': '193', 'series': [], 'country_code': 'US', 'language_code': 'eng', 'popular_shelves': [{'count': '450', 'name': 'to-read'}, {'count': '64', 'name': 'picture-books'}, {'count': '26', 'name': 'animals'}, {'count': '22', 'name': 'children-s-books'}, {'count': '21', 'name': 'childrens'}, {'count': '20', 'name': 'dogs'}, {'count': '18', 'name': 'death'}, {'count': '17', 'name': 'children'}, {'count': '16', 'name': 'picture-book'}, {'count': '12', 'name': 'children-s'}, {'count': '12', 'name': 'favorites'}, {'count': '10', 'name': 'kids'}, {'count': '8', 'name': 'currently-reading'}, {'count': '8', 'name': 'pets'}, {'count': '8', 'name': 'children-s-lit'}, {'count': '8', 'name': 'fiction'}, {'count': '8', 'name': 'childrens-books'}, {'count': '7', 'name': 'heaven'}, {'count': '7', 'name': 'dog-books'}, {'count': '6', 'name': 'children-s-literature'}, {'count': '5', 'name': 'cynthia-rylant'}, {'count': '5', 'name': 'grief'}, {'count': '4', 'name': 'default'}, {'count': '4', 'name': 'library'}, {'count': '3', 'name': 'kids-books'}, {'count': '3', 'name': 'bibliotherapy'}, {'count': '3', 'name': 'religion'}, {'count': '3', 'name': 'diversity-inclusion'}, {'count': '3', 'name': 'childrens-lit'}, {'count': '3', 'name': 'books-i-own'}, {'count': '2', 'name': 'death-grief'}, {'count': '2', 'name': 'picture-story-books'}, {'count': '2', 'name': 'children-s-picture'}, {'count': '2', 'name': 'kiddos'}, {'count': '2', 'name': 'spirituality'}, {'count': '2', 'name': 'loss-of-a-pet'}, {'count': '2', 'name': 'childhood'}, {'count': '2', 'name': 'school-counseling'}, {'count': '2', 'name': 'classroom-library'}, {'count': '2', 'name': 'self-help'}, {'count': '2', 'name': 'young-children'}, {'count': '2', 'name': 'unfortunate-events'}, {'count': '2', 'name': 'helpful'}, {'count': '2', 'name': 'appreciation'}, {'count': '2', 'name': 'acceptance'}, {'count': '2', 'name': 'ece-3601'}, {'count': '2', 'name': 'class-library'}, {'count': '2', 'name': 'closet'}, {'count': '2', 'name': '813-5'}, {'count': '2', 'name': 'classroom'}, {'count': '2', 'name': 'dog-tales'}, {'count': '2', 'name': 'christian'}, {'count': '2', 'name': 'angels'}, {'count': '2', 'name': 'non-fiction'}, {'count': '2', 'name': 'illustrated'}, {'count': '2', 'name': 'children-s-book'}, {'count': '2', 'name': 'god'}, {'count': '2', 'name': 'animal-books'}, {'count': '2', 'name': 'picture'}, {'count': '2', 'name': 'kid-books'}, {'count': '2', 'name': 'children-s-picture-books'}, {'count': '2', 'name': 'childrens-favorites'}, {'count': '1', 'name': 'year-2017'}, {'count': '1', 'name': 'l'}, {'count': '1', 'name': 'at-library'}, {'count': '1', 'name': 'to-read-fiction'}, {'count': '1', 'name': 'h-h-s'}, {'count': '1', 'name': 'a2'}, {'count': '1', 'name': 'a'}, {'count': '1', 'name': 'kids-and-teen'}, {'count': '1', 'name': 'zone-2'}, {'count': '1', 'name': 'teach-writing'}, {'count': '1', 'name': 'read-fiction-child'}, {'count': '1', 'name': 'premiere-wishlist'}, {'count': '1', 'name': 'picturebooks'}, {'count': '1', 'name': 'my-library-own'}, {'count': '1', 'name': 'mg-ya-picture-books-fiction'}, {'count': '1', 'name': 'mental-health-resources-for-kids'}, {'count': '1', 'name': 'littles'}, {'count': '1', 'name': 'kids-fiction'}, {'count': '1', 'name': 'kids-family'}, {'count': '1', 'name': 'elem-early'}, {'count': '1', 'name': 'dogs-animals'}, {'count': '1', 'name': 'death-dying-grief'}, {'count': '1', 'name': 'childrens_picture-books'}, {'count': '1', 'name': 'childrens-fiction'}, {'count': '1', 'name': 'books-about-scary-stuff'}, {'count': '1', 'name': 'best-secular-judaica-resources'}, {'count': '1', 'name': 'author-study-cynthia-rylant'}, {'count': '1', 'name': 'animals-picture-book'}, {'count': '1', 'name': 'animal-tales'}, {'count': '1', 'name': 'alex-s-books-at-5-6'}, {'count': '1', 'name': 'age-slastic_50_1gr'}, {'count': '1', 'name': 'afterlife-literature'}, {'count': '1', 'name': '1000bb4k'}, {'count': '1', 'name': 'kids-read'}, {'count': '1', 'name': 'kids-recommend-gr1-2-c-t-l'}, {'count': '1', 'name': 'mortality'}, {'count': '1', 'name': 'izzy-s-summer-1-000'}, {'count': '1', 'name': 'k-2'}], 'asin': '', 'is_ebook': 'false', 'average_rating': '4.43', 'kindle_asin': 'B017RORXNI', 'similar_books': ['834493', '452189', '140185', '1897316', '2189812', '424619', '6424103', '1071898', '269418', '153165', '197998', '130878', '1241617', '209635', '15168', '666880', '1680823', '1081530'], 'description': \"In Newbery Medalist Cynthia Rylant's classic bestseller, the author comforts readers young and old who have lost a dog. Recommended highly by pet lovers around the world, Dog Heaven not only comforts but also brings a tear to anyone who is devoted to a pet. From expansive fields where dogs can run and run to delicious biscuits no dog can resist, Rylant paints a warm and affectionate picture of the ideal place God would, of course, create for man's best friend. The first picture book illustrated by the author, Dog Heaven is enhanced by Rylant's bright, bold paintings that perfectly capture an afterlife sure to bring solace to anyone who is grieving.\", 'format': 'Hardcover', 'link': 'https://www.goodreads.com/book/show/89378.Dog_Heaven', 'authors': [{'author_id': '5411', 'role': ''}], 'publisher': 'Blue Sky Press', 'num_pages': '40', 'publication_day': '1', 'isbn13': '9780590417013', 'publication_month': '9', 'edition_information': '', 'publication_year': '1995', 'url': 'https://www.goodreads.com/book/show/89378.Dog_Heaven', 'image_url': 'https://images.gr-assets.com/books/1360057676m/89378.jpg', 'book_id': '89378', 'ratings_count': '1331', 'work_id': '86259', 'title': 'Dog Heaven', 'title_without_series': 'Dog Heaven'}]\n"
     ]
    }
   ],
   "source": [
    "#jason datei impotieren und schauen ob alles passt \n",
    "\n",
    "data = []  # Initialize an empty list to store the JSON objects\n",
    "with open('data/first_30_complete_entries.json', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Append each JSON object to the list\n",
    "        data.append(json.loads(line.strip()))  # Use strip() to remove any leading/trailing whitespace\n",
    "\n",
    "# Now, data should be a list of dictionaries\n",
    "print(type(data))  # Should be <class 'list'>\n",
    "print(data[:2])    # Should display the first two book dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total books processed: 38633\n",
      "Filtered books: 22582\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Angenommen, `data` ist deine große JSON-Datei, die bereits in eine Liste von Dictionaries geladen wurde.\n",
    "\n",
    "# Step 1: Create a set of all unique book IDs in the dataset\n",
    "all_book_ids = {buch['book_id'] for buch in data}\n",
    "\n",
    "# Step 2: Create a mapping of book IDs to their indices\n",
    "book_id_to_index = {book_id: index for index, book_id in enumerate(all_book_ids)}\n",
    "\n",
    "# Step 3: Prepare a dictionary to hold the filtered books and multi-label targets\n",
    "filtered_books_dict = {}\n",
    "multi_label_targets = []\n",
    "\n",
    "# Prepare a list to track missing similar books\n",
    "missing_similar_books = []\n",
    "\n",
    "# Process each book in the dataset\n",
    "for buch in data:\n",
    "    # Sicherstellen, dass 'similar_books' vorhanden ist und eine Liste ist\n",
    "    if 'similar_books' not in buch or not isinstance(buch['similar_books'], list):\n",
    "        continue\n",
    "    \n",
    "    # Filter similar_books to retain only those that exist in all_book_ids\n",
    "    valid_similar_books = [sim_book for sim_book in buch['similar_books'] if sim_book in all_book_ids]\n",
    "\n",
    "    # Nur das Buch zu filtered_books_dict hinzufügen, wenn mindestens ein gültiger similar_book vorhanden ist\n",
    "    if valid_similar_books:\n",
    "        filtered_books_dict[buch['book_id']] = {\n",
    "            'title': buch.get('title'),\n",
    "            'authors': [author['author_id'] for author in buch.get('authors', [])],\n",
    "            'description': buch.get('description'),\n",
    "            'similar_books': valid_similar_books  # Behalte nur gültige similar book IDs\n",
    "        }\n",
    "\n",
    "        # Erstelle einen multi-hot kodierten Vektor für die gültigen similar_books\n",
    "        target_vector = np.zeros(len(all_book_ids), dtype=int)\n",
    "        for similar_book_id in valid_similar_books:\n",
    "            target_vector[book_id_to_index[similar_book_id]] = 1\n",
    "        multi_label_targets.append(target_vector)\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = 'data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the filtered books to a JSON file\n",
    "output_file_path = os.path.join(output_dir, 'filtered_books.json')\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(filtered_books_dict, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Output statistics\n",
    "print(f\"Total books processed: {len(data)}\")\n",
    "print(f\"Filtered books: {len(filtered_books_dict)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows saved: 23559\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Open the JSON file and load the data\n",
    "with open('data/filtered_books.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Step 1: Create a set of all unique book IDs in the dataset\n",
    "all_book_ids = set(data.keys())\n",
    "\n",
    "for book_id, book_info in data.items():\n",
    "    # Handle multiple similar books\n",
    "    for similar_book in book_info.get('similar_books', []):\n",
    "        # Only create a new row if the similar book ID exists in all_book_ids\n",
    "        if similar_book in all_book_ids:\n",
    "            rows.append({\n",
    "                'book_id': book_id,\n",
    "                'title': book_info['title'],\n",
    "                'authors': ', '.join(book_info.get('authors', [])),  # Join authors if there are multiple\n",
    "                'description': book_info['description'],\n",
    "                'similar_book': similar_book\n",
    "            })\n",
    "\n",
    "# Create a DataFrame from the rows\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('data/books.csv', index=False)\n",
    "\n",
    "# Output the number of rows saved\n",
    "print(f\"Total rows saved: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of         book_id                          title                 authors  \\\n",
       "0         89378                     Dog Heaven                    5411   \n",
       "1       2008910          Buenos días, tristeza                 1357577   \n",
       "2      18628480                         Stoner  51229, 110982, 5768434   \n",
       "3      18628480                         Stoner  51229, 110982, 5768434   \n",
       "4      18628480                         Stoner  51229, 110982, 5768434   \n",
       "...         ...                            ...                     ...   \n",
       "23554    836042                           1984           3706, 4464400   \n",
       "23555    344972  The Life and Times of Chaucer                  481146   \n",
       "23556   9884033               The Killing Hour            18282, 62817   \n",
       "23557   9884033               The Killing Hour            18282, 62817   \n",
       "23558  17779550         Last Train to Istanbul        2882488, 7213767   \n",
       "\n",
       "                                             description  similar_book  \n",
       "0      In Newbery Medalist Cynthia Rylant's classic b...        130878  \n",
       "1      En una hermosa mansion a orillas del Mediterra...        819956  \n",
       "2      Stoner e il racconto della vita di un uomo tra...       3979476  \n",
       "3      Stoner e il racconto della vita di un uomo tra...       8320645  \n",
       "4      Stoner e il racconto della vita di un uomo tra...        154869  \n",
       "...                                                  ...           ...  \n",
       "23554  '1984' nao e apenas mais um livro sobre politi...        480204  \n",
       "23555  The facts about Geoffrey Chaucer's life are pl...        134026  \n",
       "23556  Each time he struck, he took two victims. Day ...        545881  \n",
       "23557  Each time he struck, he took two victims. Day ...         84833  \n",
       "23558  International bestseller by one of Turkey's mo...       1285217  \n",
       "\n",
       "[23559 rows x 5 columns]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/books.csv')\n",
    "df.info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle ähnlichen Buch-IDs sind in den Buch-IDs vorhanden: True\n",
      "Anzahl der fehlenden Bücher: 0\n",
      "Fehlende Buch-IDs: set()\n"
     ]
    }
   ],
   "source": [
    "book_ids = set(df['book_id'])\n",
    "similar_book_ids = set(df['similar_book'])\n",
    "\n",
    "# Step 2: Find missing similar book IDs\n",
    "missing_books = similar_book_ids - book_ids\n",
    "missing_count = len(missing_books)\n",
    "\n",
    "# Step 3: Check if every similar book ID is present in the book ID set\n",
    "all_similar_in_books = similar_book_ids.issubset(book_ids)\n",
    "\n",
    "print(\"Alle ähnlichen Buch-IDs sind in den Buch-IDs vorhanden:\", all_similar_in_books)\n",
    "print(\"Anzahl der fehlenden Bücher:\", missing_count)\n",
    "print(\"Fehlende Buch-IDs:\", missing_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der verbleibenden Zeilen nach dem Droppen: 19025\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Erstelle eine Menge aller vorhandenen Buch-IDs und ähnlichen Buch-IDs\n",
    "book_ids = set(df['book_id'])\n",
    "similar_book_ids = set(df['similar_book'])\n",
    "\n",
    "# Step 2: Finde die fehlenden ähnlichen Buch-IDs\n",
    "missing_books = similar_book_ids - book_ids\n",
    "\n",
    "# Step 3: Droppen der Zeilen, bei denen die similar_book-ID in missing_books enthalten ist\n",
    "df = df[~df['similar_book'].isin(missing_books)]\n",
    "\n",
    "# Ausgabe der Anzahl der verbleibenden Zeilen\n",
    "print(f\"Anzahl der verbleibenden Zeilen nach dem Droppen: {len(df)}\")\n",
    "\n",
    "# Optional: Speichern der gefilterten Daten in eine neue CSV-Datei\n",
    "df.to_csv('data/filtered_books_fina1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check NAs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "missing_description_count = df['description'].isnull().sum()\n",
    "print(missing_description_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtanzahl der fehlenden Werte: 0\n"
     ]
    }
   ],
   "source": [
    "total_missing = df.isnull().sum().sum()\n",
    "print(f\"Gesamtanzahl der fehlenden Werte: {total_missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_id         0\n",
      "title           0\n",
      "authors         0\n",
      "description     0\n",
      "similar_book    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_per_column = df.isnull().sum()\n",
    "print(missing_per_column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# types checken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_id          int64\n",
       "title           object\n",
       "authors         object\n",
       "description     object\n",
       "similar_book     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/filtered_books_fina1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Lade das englische Modell\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Annahme: df ist dein DataFrame\n",
    "# Entferne Stoppwörter aus der 'description'-Spalte\n",
    "df['description'] = df['description'].apply(lambda x: ' '.join([token.text for token in nlp(x) if not token.is_stop]))\n",
    "\n",
    "# Entferne Stoppwörter aus der 'title'-Spalte\n",
    "df['title'] = df['title'].apply(lambda x: ' '.join([token.text for token in nlp(x) if not token.is_stop]))\n",
    "\n",
    "# Speichere die bearbeiteten Daten in einer neuen CSV-Datei\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "<class 'str'>    19025\n",
      "Name: count, dtype: int64\n",
      "Empty DataFrame\n",
      "Columns: [book_id, title, authors, description, similar_book]\n",
      "Index: []\n",
      "Number of empty strings in title: 57\n"
     ]
    }
   ],
   "source": [
    "print(df['title'].apply(type).value_counts())\n",
    "\n",
    "\n",
    "non_string_entries = df[~df['title'].apply(lambda x: isinstance(x, str))]\n",
    "print(non_string_entries)\n",
    "\n",
    "df['title'] = df['title'].astype(str)\n",
    "\n",
    "empty_count = (df['title'] == '').sum()\n",
    "print(f'Number of empty strings in title: {empty_count}')\n",
    "\n",
    "df['title'] = df['title'].apply(lambda x: ' '.join([token.text for token in nlp(x) if not token.is_stop]) if isinstance(x, str) else '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty strings in title after removal: 0\n"
     ]
    }
   ],
   "source": [
    "# Remove rows where 'title' is an empty string\n",
    "df = df[df['title'] != '']\n",
    "\n",
    "# Check the number of empty strings in 'title' after removal\n",
    "num_empty_titles = df['title'].eq('').sum()\n",
    "print(f'Number of empty strings in title after removal: {num_empty_titles}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13154\n"
     ]
    }
   ],
   "source": [
    "unique_book_ids = df['book_id'].nunique()  # Get the number of unique book IDs\n",
    "print(unique_book_ids)  # Print the count of unique book IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/filtered_books_fina1.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
